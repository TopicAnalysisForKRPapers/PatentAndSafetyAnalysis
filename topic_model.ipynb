{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:13.390316500Z",
     "start_time": "2023-06-14T04:30:12.474803400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is jupyter version of the code\n",
    "# modified from github repo: treform\n",
    "%pip install pyvis --user\n",
    "%pip install treform --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:13.437677700Z",
     "start_time": "2023-06-14T04:30:13.390316500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WANTED_TOPIC_COUNT = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:13.437677700Z",
     "start_time": "2023-06-14T04:30:13.406343500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "CSV_PATH = os.path.join(r'.', 'result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:17.134839300Z",
     "start_time": "2023-06-14T04:30:13.437677700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from treform.topic_model.pyTextMinerTopicModel import pyTextMinerTopicModel\n",
    "import treform as ptm\n",
    "import tomotopy as tp\n",
    "from tqdm import tqdm\n",
    "#import Komoran\n",
    "from treform.tokenizer import Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:17.134839300Z",
     "start_time": "2023-06-14T04:30:17.104518Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    def __init__(self, textList):\n",
    "        self.pair_map = {}\n",
    "        self.docs = textList\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.docs.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.docs.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:17.134839300Z",
     "start_time": "2023-06-14T04:30:17.134839300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "class CorpusFromFieldDelimitedFileWithYear(Corpus):\n",
    "    def __init__(self, file, doc_index=1, year_index=2, delimiter='\\t'):\n",
    "        array = []\n",
    "        id = 0\n",
    "        pair_map = {}\n",
    "        # read file from csv reader\n",
    "        with open(file, encoding='utf-8') as ins:\n",
    "            reader = csv.reader(ins)\n",
    "            for fields in reader:\n",
    "                try:\n",
    "                    array.append(fields[doc_index])\n",
    "                    pair_map[id] = fields[year_index]\n",
    "                    id += 1\n",
    "                except IndexError:\n",
    "                    print(\"out of index \" + str(id))\n",
    "\n",
    "        self.docs = array\n",
    "        self.pair_map = pair_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:17.150424600Z",
     "start_time": "2023-06-14T04:30:17.134839300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StopwordFilterBeta:\n",
    "    IN_TYPE = [list, str]\n",
    "    OUT_TYPE = [list, str]\n",
    "\n",
    "    def __init__(self, stopwords = [], file = None):\n",
    "        if file:\n",
    "            stopwords = stopwords + [line.strip() for line in open(file, encoding='utf-8')]\n",
    "        self.stopwords = set(stopwords)\n",
    "        self.stopwordsPrefix = ('http', 'https', 'ftp', 'git', 'thatt')\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        #any(e for e in test_list if e.startswith('three') or e.endswith('four'))\n",
    "        return [i for i in args[0] if len(i) > 1 and i.lower() not in self.stopwords and (i.lower().startswith(tuple(p for p in self.stopwordsPrefix)) == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:17.166071200Z",
     "start_time": "2023-06-14T04:30:17.150424600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:17.213507600Z",
     "start_time": "2023-06-14T04:30:17.166071200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corpus = ptm.CorpusFromFieldDelimitedFileWithYear(PathManager.get('../sample_data/sample_dmr_input.txt'),doc_index=2,year_index=1)\n",
    "\n",
    "corpus = CorpusFromFieldDelimitedFileWithYear(CSV_PATH, doc_index= 4, year_index=2, delimiter=',')\n",
    "pair_map = corpus.pair_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:17.229243300Z",
     "start_time": "2023-06-14T04:30:17.213507600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(corpus.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:19.672738200Z",
     "start_time": "2023-06-14T04:30:17.229243300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = ptm.Pipeline(ptm.splitter.NLTK(),\n",
    "                        Komoran(), # MeCab, Komoran, Okt, etc...\n",
    "                        # Mecab requires manual installation! try eunjeon if you can\n",
    "                        ptm.helper.POSFilter('NN*'), # Noun\n",
    "                        ptm.helper.SelectWordOnly(),\n",
    "                        StopwordFilterBeta(file=r'stopwordsKor_riss.txt')\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:57.446333900Z",
     "start_time": "2023-06-14T04:30:19.672738200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pipeline.processCorpus(tqdm(corpus.docs))\n",
    "text_data = []\n",
    "for doc in result:\n",
    "    new_doc = []\n",
    "    for sent in doc:\n",
    "        for _str in sent:\n",
    "            if len(_str) > 0:\n",
    "                new_doc.append(_str)\n",
    "    text_data.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:57.508713400Z",
     "start_time": "2023-06-14T04:30:57.446333900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for doc in tqdm(result):\n",
    "    new_doc = []\n",
    "    for sent in doc:\n",
    "        for _str in sent:\n",
    "            if len(_str) > 0:\n",
    "                new_doc.append(_str)\n",
    "    text_data.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:57.524469800Z",
     "start_time": "2023-06-14T04:30:57.508713400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_data[:11] # example of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:30:58.492799300Z",
     "start_time": "2023-06-14T04:30:57.524469800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get memory size of text data\n",
    "import sys\n",
    "import os\n",
    "#print(sys.getsizeof(text_data))\n",
    "# pickle if smaller than 1GB\n",
    "# if text_data.pickle does not exist, it will be created\n",
    "# check if text_data.pickle exists\n",
    "if os.path.isfile('text_data.pickle'):\n",
    "    import pickle\n",
    "    with open('text_data.pickle', 'rb') as f:\n",
    "        text_data = pickle.load(f)\n",
    "else:\n",
    "    if sys.getsizeof(text_data) < 1<<30:\n",
    "        import pickle\n",
    "        with open('text_data.pickle', 'wb') as f:\n",
    "            pickle.dump(text_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:31:08.731419400Z",
     "start_time": "2023-06-14T04:30:58.495314900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_model = pyTextMinerTopicModel()\n",
    "topic_number = WANTED_TOPIC_COUNT\n",
    "#dominant_topic_number = 6\n",
    "#if dominant_topic_number >= topic_number:\n",
    "#    dominant_topic_number = topic_number - 1\n",
    "\n",
    "mdl=None\n",
    "#mode is either lda, dmr, hdp, infer, ct, visualize, etc\n",
    "\n",
    "mode='lda'\n",
    "label = ''\n",
    "if mode == 'lda':\n",
    "    #LDA\n",
    "    print('Running LDA')\n",
    "    label='LDA'\n",
    "    lda_model_name = './test.lda.bin'\n",
    "    mdl=topic_model.lda_model(text_data, lda_model_name, topic_number)\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'dmr':\n",
    "    #DMR\n",
    "    print('Running DMR')\n",
    "    label='DMR'\n",
    "    dmr_model_name='./test.dmr.bin'\n",
    "    mdl=topic_model.dmr_model(text_data, pair_map, dmr_model_name, topic_number)\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'hdp':\n",
    "    print('Running HDP')\n",
    "    label='HDP'\n",
    "    hdp_model_name='./test.hdp.bin'\n",
    "    mdl, topic_num=topic_model.hdp_model(text_data, hdp_model_name)\n",
    "    topic_number=topic_num\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'hlda':\n",
    "    print('Running HLDA')\n",
    "    label='HLDA'\n",
    "    hlda_model_name = './test.hlda.bin'\n",
    "    mdl=topic_model.hlda_model(text_data, hlda_model_name)\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'ct':\n",
    "    print('Running CT')\n",
    "    label = 'CT'\n",
    "    ct_model_name = './test.ct.bin'\n",
    "    save_file = 'D:/python_workspace/treform/topic_network.html'\n",
    "    mdl = topic_model.ct_model(text_data, ct_model_name, topic_number=topic_number, topic_network_result=save_file)\n",
    "\n",
    "elif mode == 'infer':\n",
    "    lda_model_name = './test.lda.bin'\n",
    "    unseen_text='아사이 베리 블루베리 비슷하다'\n",
    "    topic_model.inferLDATopicModel(lda_model_name, unseen_text)\n",
    "\n",
    "else:\n",
    "    print('No mode is selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:31:08.778294500Z",
     "start_time": "2023-06-14T04:31:08.731419400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:31:18.733450800Z",
     "start_time": "2023-06-14T04:31:08.747057600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mode = 'lda'\n",
    "model_name = f'./test.{mode}.bin'\n",
    "topic_number = WANTED_TOPIC_COUNT\n",
    "if locals().get('topic_model') is None:\n",
    "    topic_model = pyTextMinerTopicModel()\n",
    "\n",
    "mdl = tp.LDAModel.load(model_name)\n",
    "print(\"Model loaded\")\n",
    "mdl.load(model_name)\n",
    "# The below code extracts this dominant topic for each sentence\n",
    "# and shows the weight of the topic and the keywords in a nicely formatted output.\n",
    "df_topic_sents_keywords, matrix = pyTextMinerTopicModel().format_topics_sentences(topic_number=topic_number, mdl=mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:31:18.746494100Z",
     "start_time": "2023-06-14T04:31:18.733450800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(df_topic_sents_keywords)\n",
    "if sys.getsizeof(df_topic_sents_keywords) < 1<<30:\n",
    "    import pickle\n",
    "    with open('df_topic_sents_keywords.pickle', 'wb') as f:\n",
    "        pickle.dump(df_topic_sents_keywords, f)\n",
    "else:\n",
    "    print('df_topic_sents_keywords is too big to dump')\n",
    "# Now dump matrix if it is smaller than 1GB\n",
    "if sys.getsizeof(matrix) < 1<<30:\n",
    "    import pickle\n",
    "    with open('matrix.pickle', 'wb') as f:\n",
    "        pickle.dump(matrix, f)\n",
    "else:\n",
    "    print('matrix is too big to dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:31:18.762182900Z",
     "start_time": "2023-06-14T04:31:18.746494100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "def tSNE(mdl, matrix, label, topic_number=10):\n",
    "    from bokeh.plotting import figure, output_file, show\n",
    "    from bokeh.models import Label\n",
    "    from bokeh.io import output_notebook\n",
    "    import matplotlib.colors as mcolors\n",
    "    from sklearn.manifold import TSNE\n",
    "\n",
    "    # Array of topic weights\n",
    "    arr = pd.DataFrame(matrix).fillna(0).values\n",
    "\n",
    "    # Dominant topic number in each doc\n",
    "    topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "    # tSNE Dimension Reduction\n",
    "    tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "    tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "    n_topics = topic_number\n",
    "    mycolors = np.array([color for name, color in matplotlib.colors.cnames.items()])\n",
    "    plot = figure(title=\"t-SNE Clustering of {} \" + label + \"Topics\".format(n_topics),\n",
    "                  width=900, height=700)\n",
    "\n",
    "    plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "\n",
    "    show(plot)\n",
    "topic_model.tSNE = tSNE # monkey patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:31:18.777766600Z",
     "start_time": "2023-06-14T04:31:18.762182900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_topic_model(topic_model, mdl, matrix, label=''):\n",
    "    import pickle\n",
    "    with open('df_topic_sents_keywords.pickle', 'rb') as f:\n",
    "        df_topic_sents_keywords = pickle.load(f)\n",
    "    # Format\n",
    "    df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "    df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "    df_dominant_topic.head(WANTED_TOPIC_COUNT)\n",
    "\n",
    "    # Sometimes we want to get samples of sentences that most represent a given topic.\n",
    "    # This code gets the most exemplar sentence for each topic.\n",
    "    dist_result_file_ = f'./dist_doc_word_count{label}.png'\n",
    "    topic_model.distribution_document_word_count(df_topic_sents_keywords, df_dominant_topic, result_file=dist_result_file_)\n",
    "\n",
    "    #When working with a large number of documents,\n",
    "    # we want to know how big the documents are as a whole and by topic.\n",
    "    #Let’s plot the document word counts distribution.\n",
    "    dominant_result_file_ = f'./dominant_topic_word_count{label}.png'\n",
    "    dominant_topic_number = 7\n",
    "    topic_model.distribution_word_count_by_dominant_topic(df_dominant_topic,dominant_topic_number=dominant_topic_number, result_file=dominant_result_file_)\n",
    "\n",
    "    # Though we’ve already seen what are the topic keywords in each topic,\n",
    "    # a word cloud with the size of the words proportional to the weight is a pleasant sight.\n",
    "    # The coloring of the topics I’ve taken here is followed in the subsequent plots as well.\n",
    "    topic_cloud_result_file = f'./topic_word_cloud{label}.png'\n",
    "    topic_number = mdl.k\n",
    "    topic_model.word_cloud_by_topic(mdl, topic_number=topic_number,topic_cloud_result_file=topic_cloud_result_file)\n",
    "\n",
    "    topic_keyword_result_file = f'./topic_keyword{label}.png'\n",
    "    # Let’s plot the word counts and the weights of each keyword in the same chart.\n",
    "    topic_model.word_count_by_keywords(mdl,matrix,topic_keyword_result_file=topic_keyword_result_file, topic_number=topic_number)\n",
    "\n",
    "    topics_per_document = f'./topic_per_document{label}.png'\n",
    "    topic_model.topics_per_document(mdl, start=0, end=WANTED_TOPIC_COUNT, topics_per_document=topics_per_document, topic_number=topic_number)\n",
    "\n",
    "    #visualize documents by tSNE\n",
    "    topic_model.tSNE(mdl,matrix,'',topic_number=topic_number)\n",
    "\n",
    "    visualization_file=f'./topic_visualization{label}.html'\n",
    "    topic_model.make_pyLDAVis(mdl,visualization_file=visualization_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:31:18.793475800Z",
     "start_time": "2023-06-14T04:31:18.777766600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize(mode, topic_number, topic_model=None, return_matrix=False):\n",
    "    model_name = f'./test.{mode}.bin'\n",
    "    topic_number = WANTED_TOPIC_COUNT\n",
    "    if locals().get('topic_model') is None:\n",
    "        topic_model = pyTextMinerTopicModel()\n",
    "    if model_name == './test.lda.bin':\n",
    "        mdl = tp.LDAModel.load(model_name)\n",
    "        print(\"Model loaded\")\n",
    "    elif model_name == './test.dmr.bin':\n",
    "        mdl = tp.DMRModel.load(model_name)\n",
    "        visual_result_file1= './dmr_line_graph.png'\n",
    "        visual_result_file2 = './dmr_bar_graph.png'\n",
    "        pyTextMinerTopicModel().visualizeDMR(mdl,visual_result1=visual_result_file1, visual_result2=visual_result_file2)\n",
    "    elif model_name == './test.ct.bin':\n",
    "        mdl = tp.CTModel.load(model_name)\n",
    "        result_file = './topic_network.html'\n",
    "        topic_model.visualize_ct_model(mdl, topic_network_result=result_file)\n",
    "    else:\n",
    "        raise Exception(\"Cannot visualize this model {}\".format(model_name))\n",
    "    if return_matrix:\n",
    "        df_topic_sents_keywords, matrix = pyTextMinerTopicModel().format_topics_sentences(topic_number=topic_number, mdl=mdl)\n",
    "    else:\n",
    "        matrix = None\n",
    "    return mdl, matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:31:18.808990300Z",
     "start_time": "2023-06-14T04:31:18.793475800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:31:32.685811100Z",
     "start_time": "2023-06-14T04:31:18.808990300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now DMR\n",
    "\n",
    "# load from 'text_data.pickle'\n",
    "import pickle\n",
    "with open('text_data.pickle', 'rb') as f:\n",
    "    text_data = pickle.load(f)\n",
    "corpus = CorpusFromFieldDelimitedFileWithYear(CSV_PATH, doc_index=4, year_index=2, delimiter=',')\n",
    "pair_map = corpus.pair_map\n",
    "mode = 'lda'\n",
    "print('Running DMR')\n",
    "label='DMR'\n",
    "dmr_model_name='./test.dmr.bin'\n",
    "mdl=pyTextMinerTopicModel().dmr_model(text_data, pair_map, dmr_model_name, WANTED_TOPIC_COUNT, iteration = 2500)\n",
    "print('perplexity score ' + str(mdl.perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:32:32.870215200Z",
     "start_time": "2023-06-14T04:32:15.620495600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now visualize\n",
    "model, matrix = visualize(mode, WANTED_TOPIC_COUNT, mdl, return_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:32:44.952298500Z",
     "start_time": "2023-06-14T04:32:44.844717800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T04:33:22.855996100Z",
     "start_time": "2023-06-14T04:32:47.354599400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if matrix does not exist, pickle\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "if not os.path.exists('matrix.pickle'):\n",
    "    print('matrix does not exist, pickle')\n",
    "    if sys.getsizeof(matrix) > 100000000:\n",
    "        print('matrix is too big, skip')\n",
    "    else:\n",
    "        with open('matrix.pickle', 'wb') as f:\n",
    "            pickle.dump(matrix, f)\n",
    "topic_model = pyTextMinerTopicModel()\n",
    "topic_model.tSNE = tSNE # monkey patching\n",
    "visualize_topic_model(topic_model, mdl, matrix, label='DMR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
